{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da88575",
   "metadata": {},
   "source": [
    "<Font size =5> Creating a dataset for the past 365 days using a Nepse API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80b5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arses\\Desktop\\Forecast\\venv\\Lib\\site-packages\\nepse_scraper\\Scraper.py:10: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for 2024-08-24\n",
      "Collected data for 2024-08-25\n",
      "Collected data for 2024-08-26\n",
      "Collected data for 2024-08-27\n",
      "Collected data for 2024-08-28\n",
      "Collected data for 2024-08-29\n",
      "Collected data for 2024-08-30\n",
      "Collected data for 2024-08-31\n",
      "Collected data for 2024-09-01\n",
      "Collected data for 2024-09-02\n",
      "Collected data for 2024-09-03\n",
      "Collected data for 2024-09-04\n",
      "Collected data for 2024-09-05\n",
      "Collected data for 2024-09-06\n",
      "Collected data for 2024-09-07\n",
      "Collected data for 2024-09-08\n",
      "Collected data for 2024-09-09\n",
      "Collected data for 2024-09-10\n",
      "Collected data for 2024-09-12\n",
      "Collected data for 2024-09-13\n",
      "Collected data for 2024-09-14\n",
      "Collected data for 2024-09-15\n",
      "Collected data for 2024-09-16\n",
      "Collected data for 2024-09-17\n",
      "Collected data for 2024-09-18\n",
      "Collected data for 2024-09-19\n",
      "Collected data for 2024-09-20\n",
      "Collected data for 2024-09-21\n",
      "Collected data for 2024-09-22\n",
      "Collected data for 2024-09-23\n",
      "Collected data for 2024-09-24\n",
      "Collected data for 2024-09-25\n",
      "Collected data for 2024-09-26\n",
      "Collected data for 2024-09-27\n",
      "Collected data for 2024-09-28\n",
      "Collected data for 2024-09-29\n",
      "Collected data for 2024-09-30\n",
      "Collected data for 2024-10-01\n",
      "Collected data for 2024-10-02\n",
      "Collected data for 2024-10-03\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from nepse_scraper import Nepse_scraper\n",
    "\n",
    "scraper = Nepse_scraper()\n",
    "end_date = datetime.date.today()\n",
    "start_date = end_date - datetime.timedelta(days=365)\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# loop day by day\n",
    "current = start_date\n",
    "while current <= end_date:\n",
    "    try:\n",
    "        # fetch one day's snapshot\n",
    "        daily_response = scraper.get_today_price(current.strftime(\"%Y-%m-%d\"))\n",
    "        \n",
    "        # NEW: handle JSON structure with \"content\" key\n",
    "        companies = daily_response.get(\"content\", [])\n",
    "        \n",
    "        for c in companies:\n",
    "            all_data.append({\n",
    "                \"date\": c.get(\"businessDate\"),\n",
    "                \"symbol\": c.get(\"symbol\"),\n",
    "                \"securityId\": c.get(\"securityId\"),\n",
    "                \"securityName\": c.get(\"securityName\"),\n",
    "                \"open\": c.get(\"openPrice\"),\n",
    "                \"high\": c.get(\"highPrice\"),\n",
    "                \"low\": c.get(\"lowPrice\"),\n",
    "                \"close\": c.get(\"closePrice\"),\n",
    "                \"volume\": c.get(\"totalTradedQuantity\"),\n",
    "                \"turnover\": c.get(\"totalTradedValue\"),\n",
    "                \"prevClose\": c.get(\"previousDayClosePrice\"),\n",
    "                \"52wHigh\": c.get(\"fiftyTwoWeekHigh\"),\n",
    "                \"52wLow\": c.get(\"fiftyTwoWeekLow\"),\n",
    "                \"trades\": c.get(\"totalTrades\"),\n",
    "                \"avgPrice\": c.get(\"averageTradedPrice\"),\n",
    "                \"marketCap\": c.get(\"marketCapitalization\")\n",
    "            })\n",
    "        \n",
    "        print(f\"Collected data for {current}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Skipped {current}: {e}\")\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    \n",
    "    current += datetime.timedelta(days=1)\n",
    "    time.sleep(0.1)  # be polite to NEPSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe76be",
   "metadata": {},
   "source": [
    "<font size = 5> Creating target values for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e4e26a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  symbol   close  next_close  target\n",
      "0   2024-08-25  ACLBSL  1170.1      1170.0       0\n",
      "1   2024-08-27  ACLBSL  1170.0      1144.9       0\n",
      "2   2024-08-28  ACLBSL  1144.9      1138.0       0\n",
      "3   2024-08-29  ACLBSL  1138.0      1081.0       0\n",
      "4   2024-09-01  ACLBSL  1081.0      1134.2       1\n",
      "5   2024-09-02  ACLBSL  1134.2      1116.0       0\n",
      "6   2024-09-03  ACLBSL  1116.0      1095.0       0\n",
      "7   2024-09-04  ACLBSL  1095.0      1115.0       1\n",
      "8   2024-09-05  ACLBSL  1115.0      1143.0       1\n",
      "9   2024-09-08  ACLBSL  1143.0      1104.0       0\n",
      "10  2024-09-09  ACLBSL  1104.0      1081.0       0\n",
      "11  2024-09-10  ACLBSL  1081.0      1077.1       0\n",
      "12  2024-09-11  ACLBSL  1077.1      1089.0       1\n",
      "13  2024-09-12  ACLBSL  1089.0      1066.0       0\n",
      "14  2024-09-15  ACLBSL  1066.0      1031.1       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"nepse_full_1year.csv\")\n",
    "\n",
    "# Sort by symbol and date to keep order\n",
    "df = df.sort_values(by=[\"symbol\", \"date\"])\n",
    "\n",
    "# Shift close price by -1 (next dayâ€™s close)\n",
    "df[\"next_close\"] = df.groupby(\"symbol\")[\"close\"].shift(-1)\n",
    "\n",
    "# Create target column: 1 if next day close is higher, else 0\n",
    "df[\"target\"] = (df[\"next_close\"] > df[\"close\"]).astype(int)\n",
    "df.to_csv(\"nepse_full_1year.csv\", index=False)\n",
    "print(df[[\"date\", \"symbol\", \"close\", \"next_close\", \"target\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36941ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"ma_5\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.rolling(5).mean())\n",
    "df[\"volatility_10\"] = df.groupby(\"symbol\")[\"close\"].transform(lambda x: x.pct_change().rolling(10).std())\n",
    "df.to_csv(\"nepse_full_1year.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2f05b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arses\\AppData\\Local\\Temp\\ipykernel_3652\\2514602261.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='ffill')\n",
      "C:\\Users\\arses\\AppData\\Local\\Temp\\ipykernel_3652\\2514602261.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill')# 5. Build sequences (sliding windows per company)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skipping ACLBSLP: only 2 rows\n",
      " Skipping ALBSLP: only 5 rows\n",
      " Skipping ALICLP: only 2 rows\n",
      " Skipping BHCL: only 2 rows\n",
      " Skipping CBBLPO: only 2 rows\n",
      " Skipping CYCLP: only 1 rows\n",
      " Skipping CZBILP: only 7 rows\n",
      " Skipping EDBLPO: only 1 rows\n",
      " Skipping FMDBLP: only 3 rows\n",
      " Skipping GILBPO: only 1 rows\n",
      " Skipping GMFILP: only 1 rows\n",
      " Skipping GUFLPO: only 4 rows\n",
      " Skipping HBLPO: only 6 rows\n",
      " Skipping ICFCPO: only 1 rows\n",
      " Skipping IGIPO: only 3 rows\n",
      " Skipping JFLPO: only 1 rows\n",
      " Skipping JSLBBP: only 1 rows\n",
      " Skipping KMCDBP: only 3 rows\n",
      " Skipping LBBLPO: only 1 rows\n",
      " Skipping MBLPO: only 5 rows\n",
      " Skipping MDBPO: only 2 rows\n",
      " Skipping MLBBLP: only 1 rows\n",
      " Skipping MLBLPO: only 2 rows\n",
      " Skipping MLBSLP: only 1 rows\n",
      " Skipping MPFLPO: only 1 rows\n",
      " Skipping NABBCP: only 5 rows\n",
      " Skipping NABILP: only 1 rows\n",
      " Skipping NFSPO: only 1 rows\n",
      " Skipping NICLPO: only 1 rows\n",
      " Skipping NIFRAP: only 2 rows\n",
      " Skipping NLICLP: only 3 rows\n",
      " Skipping NLICP: only 4 rows\n",
      " Skipping NMLBBLP: only 5 rows\n",
      " Skipping PFLPO: only 1 rows\n",
      " Skipping RLFLPO: only 2 rows\n",
      " Skipping SAPDBLP: only 3 rows\n",
      " Skipping SBLPO: only 5 rows\n",
      " Skipping SHINEP: only 4 rows\n",
      " Skipping SICLPO: only 3 rows\n",
      " Skipping SIFCPO: only 1 rows\n",
      " Skipping SJLICP: only 2 rows\n",
      " Skipping SKBBLP: only 2 rows\n",
      " Skipping SLBBLP: only 2 rows\n",
      " Skipping SMATAP: only 7 rows\n",
      " Skipping SMBPO: only 3 rows\n",
      " Skipping SMPDAP: only 1 rows\n",
      " Skipping SNMAPO: only 4 rows\n",
      " Skipping UAILPO: only 2 rows\n",
      " Skipping UNLBP: only 4 rows\n",
      " Skipping VLBSPO: only 7 rows\n",
      " Skipping WNLBP: only 3 rows\n",
      "(224, 7, 7)\n",
      " Final shapes:\n",
      "X: (70065, 7, 7)\n",
      "y: (70065,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "feature_cols = [\"open\", \"high\", \"low\", \"close\", \"volume\", \"ma_5\", \"volatility_10\"]\n",
    "\n",
    "for feature in feature_cols:\n",
    "    df[feature] = df.groupby(\"symbol\")[feature].transform(\n",
    "        lambda x: scaler.fit_transform(x.values.reshape(-1,1)).flatten()\n",
    "    )\n",
    "\n",
    "df = df.fillna(method='ffill')\n",
    "df = df.fillna(method='bfill')# 5. Build sequences (sliding windows per company)\n",
    "def build_sequences(group, window_size=7):\n",
    "    X, y = [], []\n",
    "    data = group[feature_cols].values\n",
    "    labels = group[\"target\"].values\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i:i+window_size])\n",
    "        y.append(labels[i+window_size])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "window_size = 7\n",
    "\n",
    "valid_companies = []\n",
    "for symbol, group in df.groupby(\"symbol\"):\n",
    "    if len(group) >= window_size + 1:  # needs at least window_size + 1 rows\n",
    "        valid_companies.append(symbol)\n",
    "    else:\n",
    "        print(f\" Skipping {symbol}: only {len(group)} rows\")\n",
    "\n",
    "df = df[df[\"symbol\"].isin(valid_companies)]\n",
    "\n",
    "X_list, y_list = [], []\n",
    "\n",
    "for symbol, group in df.groupby(\"symbol\"):\n",
    "    X_sym, y_sym = build_sequences(group, window_size=7)\n",
    "    X_list.append(X_sym)\n",
    "    y_list.append(y_sym)\n",
    "\n",
    "\n",
    "print(X_list[0].shape)  # Example shapes for one company\n",
    "# Combine all companies into one dataset\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(\" Final shapes:\")\n",
    "print(\"X:\", X.shape)  # (samples, 30, num_features)\n",
    "print(\"y:\", y.shape)  # (samples,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forecast Kernel",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
